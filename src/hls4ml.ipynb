{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbaa0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import h5py\n",
    "import hls4ml\n",
    "import plotting\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from qkeras import QConv2D, QDense, QActivation\n",
    "import tensorflow_model_optimization as tfmot\n",
    "from tensorflow.keras.layers import (\n",
    "    Lambda,\n",
    "    Input,\n",
    "    Dense,\n",
    "    LeakyReLU,\n",
    "    Conv2D,\n",
    "    AveragePooling2D,\n",
    "    MaxPooling2D,\n",
    "    UpSampling2D,\n",
    "    ZeroPadding2D,\n",
    "    BatchNormalization,\n",
    "    Flatten,\n",
    "    Reshape,\n",
    "    Activation,\n",
    "    Concatenate,\n",
    "    Cropping1D\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0948b9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(location):\n",
    "    \n",
    "    # retrieve dataset from h5 file\n",
    "    h5file = h5py.File(location, \"r\")\n",
    "    data = h5file[\"jetConstituentsList\"][()]\n",
    "    features = h5file[\"particleFeatureNames\"][()]\n",
    "    target = np.copy(data)\n",
    "\n",
    "    h5file.close()\n",
    "\n",
    "    # split the data and target data\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(data, target, test_size=0.5, shuffle=True)\n",
    "\n",
    "    # reshpae the dataset\n",
    "    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)\n",
    "    Y_train = Y_train.reshape(Y_train.shape[0], Y_train.shape[1], Y_train.shape[2], 1)\n",
    "    Y_test = Y_test.reshape(Y_test.shape[0], Y_test.shape[1], Y_test.shape[2], 1)\n",
    "\n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "def create_conv_ae(latent_dim=8, quant_size=0, pruning=False):\n",
    "\n",
    "    # encoder\n",
    "    input_encoder = Input(shape=(16,3,1), name='encoder_input')\n",
    "    x = BatchNormalization()(input_encoder)\n",
    "    x = Conv2D(16, kernel_size=(3,3), use_bias=False, padding='valid')(x) if quant_size==0 \\\n",
    "        else QConv2D(16, kernel_size=(3,3), use_bias=False, padding='valid',\n",
    "                         kernel_quantizer='quantized_bits(' + str(quant_size) + ',0,1)')(x)\n",
    "    x = Activation('relu')(x) if quant_size==0 \\\n",
    "        else QActivation('quantized_relu(bits=' + str(quant_size) + ')')(x)\n",
    "    x = AveragePooling2D(pool_size=(3, 1))(x)\n",
    "    x = Conv2D(32, kernel_size=(3,1), use_bias=False, padding='same')(x) if quant_size==0 \\\n",
    "        else QConv2D(32, kernel_size=(3,1), use_bias=False, padding='same',\n",
    "                         kernel_quantizer='quantized_bits(' + str(quant_size) + ',0,1)')(x)\n",
    "    x = Activation('relu')(x) if quant_size==0 \\\n",
    "        else QActivation('quantized_relu(bits=' + str(quant_size) + ')')(x)\n",
    "    x = AveragePooling2D(pool_size=(3, 1))(x)\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    enc = Dense(latent_dim)(x)\n",
    "    encoder = Model(inputs=input_encoder, outputs=enc)\n",
    "    encoder.summary()\n",
    "\n",
    "    # decoder\n",
    "    input_decoder = Input(shape=(latent_dim,), name='decoder_input')\n",
    "    x = Dense(32)(input_decoder) if quant_size==0 \\\n",
    "        else QDense(32, kernel_quantizer='quantized_bits(' + str(quant_size) + ',2,1)',\n",
    "                    bias_quantizer='quantized_bits(' + str(quant_size) + ',2,1)')(input_decoder)\n",
    "    x = Activation('relu')(x) if quant_size==0 \\\n",
    "        else QActivation('quantized_relu(bits=' + str(quant_size) + ')')(x)\n",
    "    x = Reshape((1,1,32))(x)\n",
    "    x = UpSampling2D((4,1))(x)\n",
    "    x = Conv2D(32, kernel_size=(3,1), use_bias=False, padding='same')(x) if quant_size==0 \\\n",
    "        else QConv2D(32, kernel_size=(3,1), use_bias=False, padding='same',\n",
    "                         kernel_quantizer='quantized_bits(' + str(quant_size) + ',0,1)')(x)\n",
    "    x = Activation('relu')(x) if quant_size==0 \\\n",
    "        else QActivation('quantized_relu(bits=' + str(quant_size) + ')')(x)\n",
    "    x = Conv2D(16, kernel_size=(3,1), use_bias=False, padding='same')(x) if quant_size==0 \\\n",
    "        else QConv2D(16, kernel_size=(3,3), use_bias=False, padding='same',\n",
    "                         kernel_quantizer='quantized_bits(' + str(quant_size) + ',0,1)')(x)\n",
    "    x = Activation('relu')(x) if quant_size==0 \\\n",
    "        else QActivation('quantized_relu(bits=' + str(quant_size) + ')')(x)\n",
    "    x = UpSampling2D((4,3))(x)\n",
    "\n",
    "    dec = Conv2D(1, kernel_size=(3,3), use_bias=False, padding='same')(x) if quant_size==0 \\\n",
    "        else QConv2D(1, kernel_size=(3,3), use_bias=False, padding='same',\n",
    "                        kernel_quantizer='quantized_bits(' + str(quant_size) + ',0,1)')(x)\n",
    "    decoder = Model(inputs=input_decoder, outputs=dec)\n",
    "    decoder.summary() # AE\n",
    "    ae_outputs = decoder(encoder(input_encoder))\n",
    "    autoencoder = Model(inputs=input_encoder, outputs=ae_outputs)\n",
    "    autoencoder.summary()\n",
    "\n",
    "    if pruning:\n",
    "        pruning_schedule = tfmot.sparsity.keras.PolynomialDecay(\n",
    "                                initial_sparsity=0.0, final_sparsity=0.5,\n",
    "                                begin_step=0, end_step=40000)\n",
    "        encoder_pruned = tfmot.sparsity.keras.prune_low_magnitude(encoder, pruning_schedule=pruning_schedule)\n",
    "        encoder = encoder_pruned\n",
    "        decoder_pruned = tfmot.sparsity.keras.prune_low_magnitude(decoder, pruning_schedule=pruning_schedule)\n",
    "        decoder = decoder_pruned\n",
    "\n",
    "    # compile AE\n",
    "    autoencoder.compile(optimizer=Adam(lr=3E-3, amsgrad=True), loss='mse')\n",
    "    return autoencoder, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d500f6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------\n",
    "# Train - WIP!\n",
    "# ----------------------------------\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "# GPU config\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\n",
    "config = tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "# load dataset and split into test and train files\n",
    "X_train, X_test, Y_train, Y_test = create_dataset(\"../../data/bkg_3mln.h5\")\n",
    "\n",
    "# define callbacks\n",
    "callbacks=[\n",
    "    EarlyStopping(monitor='val_loss', patience=10, verbose=1),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, verbose=1),\n",
    "    # tfmot.sparsity.keras.UpdatePruningStep() # pruning\n",
    "]\n",
    "\n",
    "# get the CNN autoencoder\n",
    "model, encoder = create_conv_ae(quant_size=0, pruning=False)\n",
    "\n",
    "# begin training\n",
    "batch_size = 1024\n",
    "n_epochs = 20\n",
    "\n",
    "hist = model.fit(\n",
    "        x=X_train,\n",
    "        y=Y_train,\n",
    "        epochs=n_epochs,\n",
    "        batch_size=batch_size,\n",
    "        verbose=2,\n",
    "        validation_split=0.2,\n",
    "        callbacks=callbacks)\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "encoded = encoder.predict(X_test)\n",
    "\n",
    "config = hls4ml.utils.config_from_keras_model(model, granularity='model')\n",
    "print(\"-----------------------------------\")\n",
    "print(\"Configuration\")\n",
    "plotting.print_dict(config)\n",
    "print(\"-----------------------------------\")\n",
    "hls_model = hls4ml.converters.convert_from_keras_model(model,\n",
    "                                                       hls_config=config,\n",
    "                                                       output_dir='model_1/hls4ml_prj',\n",
    "                                                       fpga_part='xcu250-figd2104-2L-e')\n",
    "\n",
    "hls4ml.utils.plot_model(hls_model, show_shapes=True, show_precision=True, to_file=None)\n",
    "hls_model.compile()\n",
    "X_test = np.ascontiguousarray(X_test)\n",
    "y_hls = hls_model.predict(X_test)\n",
    "\n",
    "print(\"Keras  Accuracy: {}\".format(accuracy_score(np.argmax(Y_test, axis=1), np.argmax(pred, axis=1))))\n",
    "print(\"hls4ml Accuracy: {}\".format(accuracy_score(np.argmax(Y_test, axis=1), np.argmax(y_hls, axis=1))))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 9))\n",
    "_ = plotting.makeRoc(Y_test, pred, le.classes_)\n",
    "plt.gca().set_prop_cycle(None) # reset the colors\n",
    "_ = plotting.makeRoc(Y_test, y_hls, le.classes_, linestyle='--')\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "lines = [Line2D([0], [0], ls='-'),\n",
    "         Line2D([0], [0], ls='--')]\n",
    "from matplotlib.legend import Legend\n",
    "leg = Legend(ax, lines, labels=['keras', 'hls4ml'],\n",
    "            loc='lower right', frameon=False)\n",
    "ax.add_artist(leg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('base': conda)",
   "language": "python",
   "name": "python391jvsc74a57bd0ce84e31b18c473fd308d8459c96b336de2dcb6f92f34bf58ac4a1e1aed70b997"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
